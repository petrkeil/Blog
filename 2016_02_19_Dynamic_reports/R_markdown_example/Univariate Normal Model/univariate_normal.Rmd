---
title: "Probability Density, Likelihood, and the Normal model"
author: "Petr Keil"
date: "January 2016"
output:
  html_document:
    highlight: pygments
    number_sections: yes
    theme: cerulean
  pdf_document: default
---

The purpose of this lesson is to explain the concept of **probability density** 
and **likelihood**, using a simple example of **Normal** probability density function.

# The data

We will use data on **housefly wing length [mm]**, which you can find [here](http://www.seattlecentral.edu/qelp/sets/057/057.html). 

The original data are from Sokal & Hunter (1955) A morphometric analysis of DDT-resistant and non-resistant housefly strains *Ann. Entomol. Soc. Amer.* **48**: 499-507. 

![housefly](figure/fly.png)

To fetch the data directly from the web, run:
```{r}
wings <- read.table("http://goo.gl/4lPBG6", header=FALSE)[,1]*0.1
```

Let's examine the data:
```{r, fig.width=8, fig.height=4.5}
wings
par(mfrow=c(1,2))
hist(wings, freq=TRUE, col="grey")
points(wings, jitter(rep(0, times=100), factor=10))
hist(wings, freq=FALSE, col="grey")
points(wings, jitter(rep(0, times=100), factor=0.7))
```

```{r, echo=FALSE}
pdf(file="../../LaTeX_examples/PNAS_template/histograms.pdf", width=8, height=4)
par(mfrow=c(1,2))
hist(wings, freq=TRUE, col="grey")
points(wings, jitter(rep(0, times=100), factor=10))
hist(wings, freq=FALSE, col="grey")
points(wings, jitter(rep(0, times=100), factor=0.7))
dev.off()
```

# The Normal model

This is our formal model definition:

$$ p(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^2/(2\sigma^2)} $$

where $p()$ is **probability density function** (also known as PDF). The function has two parameters: $\mu$ (mean) and $\sigma$ (standard deviation).

For $\mu = 0$ and $\sigma = 1$ the model looks like this:
```{r, fig.width=4, fig.height=4}
  curve(dnorm, from=-4, to=4, ylab="p(x)")
```

**Remember:**

* Probability density is different from probability.

* Probability density is denoted by $p$, while probability is $P$.

* Probability density can be higher than 1.

* Probability density function must integrate to 1.

* *Probability distribution* is a very ambiguous and confusing term.

# Fitting the model to the wing data

**KEY PROBLEM:** How do we decide which parametrization is the best for our data?

```{r, fig.width=12, fig.height=4, echo=FALSE}
  par(mfrow=c(1,4))
  curve(dnorm(x, mean=1, sd=1), from=0, to=7, ylab="p(x)", ylim=c(0, 0.6),
        main="mean=1, sd=1")
    points(wings, jitter(rep(0, 100), factor=0.1))
  curve(dnorm(x, mean=4, sd=2), from=0, to=7, ylab="p(x)", ylim=c(0, 0.6),
        main="mean=4, sd=2")
    points(wings, jitter(rep(0, 100), factor=0.1))
  curve(dnorm(x, mean=2, sd=3), from=0, to=7, ylab="p(x)", ylim=c(0, 0.6),
        main="mean=2, sd=3")
    points(wings, jitter(rep(0, 100), factor=0.1))
  curve(dnorm(x, mean=4.5, sd=0.7), from=0, to=7, ylab="p(x)", ylim=c(0, 0.6),
        main="mean=4.5, sd=0.7")
    points(wings, jitter(rep(0, 100), factor=0.1))
```


## Likelihood - single data point

The *likelihood function* is the **density** evaluated at the data $x_1$, ... ,$x_n$, viewed as a function of model parameters ($\mu$ and $\sigma$ in case of the Normal model). We write it as $L(\mu, \sigma | x) = p(x | \mu, \sigma)$.  

**Calculation of likelihood in R is easy!** The R functions ```dnorm()```, ```dpois()```, ```dunif()```, ```dbinom()```, ```dgamma()```, ```dbeta()``` etc. are exactly for that!

**Example:** What is the likelihood of the first data value in the `wings` dataset,  given the $Normal(\mu=4, \sigma=1)$ model?

```{r}
my.mean = 4
my.sd = 1
```

Here is the data point that we will examine. Note that I use the letter
i to denote index:

```{r}
wings.i <- wings[1]
wings.i
```

Here is how you calculate the likelihood for the data point `wings.i` using
the function `dnorm`:
```{r}
L <- dnorm(x=wings.i, mean=my.mean, sd=my.sd)
L
```

Let's plot it:
```{r}
  curve(dnorm(x, my.mean, my.sd), from=0, to=7, 
        ylab="p(wings | mu, sigma)", xlab="wings",
        main=paste("p(wings.i | mu, sigma) = ", round(L, 4)))
  points(wings.i, 0)
  abline(v=wings.i, col="red")
  abline(h=L, col="red")
```

# Likelihood - whole dataset

Basic probability theory tells us that:

$$P(A \cap B) = P(A) \times P(B|A) = P(B) \times P(A|B) $$

Where $P(A \cap B)$ is **joint probability**, associated with *AND*, meaning
*"at the same time"*.

The problem is that joint probability for more than two events, 
e.g. $P( A \cap B \cap C \cap D )$, can be almost impossible to calculate, **with the exception of A and B being independent!** Then: 
$$P(A \cap B) = P(A) \times P(B) $$
and hence
$$ P( A \cap B \cap C \cap D ) = P(A) \times P(B) \times P(C) \times P(D)$$

It follows that it is useful to subject *probability density $p()$* to the same rules as *probability $P()$*. Hence, **we can calculate the likelihood of the whole dataset as a product of likelihoods of all individual data points!**

```{r}
  wings

  L <- dnorm(x=wings, mean=my.mean, sd=my.sd)
  L

  prod(L)
```
This is a ridiculously small number!
Which is why we have the **Negative Log Likelihood**, also known as the **deviance**:
```{r}
  - sum(log(L))
```

We can encapsulate it into a single function:
```{r}
  deviance.function <- function(x, mean, sd)
  {
    LL <- dnorm(x=x, mean=mean, sd=sd, log=TRUE) # note the log!!!
    deviance <- - sum(LL)
    return(deviance)
  }

  # it's a function of model parameters, so try to play
  # around with different paramter values
  deviance.function(wings, mean=0, sd=1)
```

Deviance (negative log-likelihood) can be then minimized (likelihood is maximized) in order to find the most likely model parameters - these are the **Maximum Likelihood Estimators (MLE)** of model parameters.

# Exercise

**Find and plot the MLE of the Normal model and the 'wings' data.** 
Use the following functions and scripts:
```{r, eval=FALSE}
 deviance.function()
 hist()
 curve()
```

# Using ```optim()``` to find MLE

`optim` needs the `deviance.function` to take only one object, which can be
a vector (or a list). So I will just put all of the data into `dat` object,
and the parameters into `par` object.

```{r}
deviance.function.for.optim <- function(par, dat)
{
  LL <- dnorm(x=dat, mean=par[1], sd=par[2], log=TRUE) # note the log!!!
  deviance <- - sum(LL)
  return(deviance)
}
```

And run the actual optimization:
```{r}
optim(par=c(mean=0,var=1), 
      fn=deviance.function.for.optim, 
      dat=wings)
```



# For further exploration

There are other functions derived from probability density functions. I have [a 
tutorial post](http://www.petrkeil.com/?p=2084) on that.

Type `?pnorm`, `?qnorm` or `?rnorm` and check it out:
